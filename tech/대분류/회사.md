★★★★★복붙할때 꼼꼼히 확인하기
특히 문서같은거 작성할때 복붙한거 단어 하나, 글자 하나 꼼꼼히 확인하기

★★★★★DB 데이터 마이그레이션할때 혹시 모르니 기존 테이블 DDL 및 데이터 꼭 백업해놓고 하기
DDL은 sql파일로 로컬에 백업해놓고, 데이터도 insert문 내보내기로 로컬에 백업해놓기

★★★★★API 만들때 간단한 거라도 API설계 문서랑 실제 결과가 똑같이 나오는지 데이터 한줄씩 확인하고, 빠진 항목은 없는지 꼭 확인하기
기존 API에 데이터 추가돼야하는 사항은 없는지 꼭 체크하기

api uri에 들어가는 영단어는 상황에 따라 다르게쓰지말고, 헷갈리지않게 똑같이 통일해서 쓰기 (과거형이라고 -ed 등 붙이는등 삼가)

★★★★★DDL 수정시 주의

10서버 로그는 ssh접속후 tail -f  log/protal-service.log 로 보기

----------------------------------------------------------------------------------------------------

10서버에 접속하려면 (or 스프링부트 어플을 켰는데 설정이 10서버를 바라보게 되어있다) 그러면 VPN을 켜야 커넥션객체를 만들때 스프링부트가 로드되면서 커넥션을 맺는데 10서버에 연결을 하려면 VPN을 켜야함

dev서버에 접속하려면 VPN을 꺼야함. 안그럼 403 에러뜸

----------------------------------------------------------------------------------------------------

dev 접속시 401 에러뜨면

https://dev.maestro-admin.okestro.cloud/
↓↓↓
https://dev.maestro-admin.okestro.cloud/local/

-----

dev 접속시 403 에러뜨면

VPN 끄기

-----

Error: connect ECONNREFUSED 10.10.10.92:8091

10 서버가 꺼져있음

ssh접속해서 sudo ./launcher.sh stop & sudo ./launcher.sh start 로 서버 가동하고 20초쯤 기다리기

----------------------------------------------------------------------------------------------------

API 요청시

------------------------------

400에러

DTO 타입(자료형) 확인

먼저 로그를 debug모드로 찍어보기
logging:
  level:
    root: debug

Integer를 Long으로 바꾸면 해결되는 경우 있음

----------------------------------------------------------------------------------------------------

오류도 안났는데

애플리케이션에서 날린 sql쿼리가 적용이 안될때는

dev로 되어있지 않은지 확인

----------------------------------------------------------------------------------------------------

주간업무보고 써야함

주간보고 컨플루언서: https://okestro.atlassian.net/wiki/spaces/DX2/pages/1327464449/
주간보고 엑셀: https://docs.google.com/spreadsheets/d/1pfse2wO5PjnouSKdSp2M86kSZnaNOpih9flJM4zDh_w/edit#gid=51259156

지라에서 이슈 만들어서

금주진행/차주진행에 지라아이디 넣고 설명 적으면 됨

----------------------------------------------------------------------------------------------------

erd를 보거나 수정하려면 먼저 sql디벨로퍼 깔아야 하고

erd 브랜치 풀 받아서 체크아웃 하고 (feature/PIND-3708-database-erd)

프로젝트 폴더 > docs > database > model > workbench 안에 vista_ti_erd.dmd 파일 열면 됨

★★★★★반대로 erd 작업 안할때는 작업브랜치에 체크아웃 해야함

----------------------------------------------------------------------------------------------------

회사에서는 jdk 17버전을 씀

17버전을 쓰는 이유는
오픈서치(엘라스틱에서 파생되어 나옴)의 최신기능이 1.8버전은 지원을 안함
최신기능을 쓰려면 1.8 보다 높은 버전을 써야하기 때문

openjdk 꺼 써도 되고 오라클꺼 써도 됨

참고로 jdk 17버전은 롱텀(LTS, 이후에 나온 버전들보다도 더 오래 지원하는) 버전이라 18보다도 지원기간이 더 길어서 좋음

------------------------------

회사에서는 스프링부트 3.X.X 버전을 씀

3.X.X 버전을 쓰려면 jdk17버전 이상을 써야함

----------------------------------------------------------------------------------------------------

외래키 제약조건은 erd상에만 연결되어있고 실제 DB에서는 모두 끊어서 사용함
↓↓↓
23년 10월 기준, 다시 연결해놓은 상태이고 복합키 참조는 외래키 연결 안해놓았음

----------------------------------------------------------------------------------------------------

DB

<10서버>
Host: 10.10.10.237
Port: 5432
User: postgres
Password: postgres
Database: vista_mon

<dev>
Host: 34.22.88.101
Port: 5432
User: vista_mon_user
Password: okestro2018
Database: vista_mon

<stg>
stg-psql-ip : 34.64.42.210
stg-psql-username : vista_mon_user
stg-psql-password : okestro2018

----------------------------------------------------------------------------------------------------

10서버

IP : 10.10.10.92
ID/PW : ubuntu/cloud1234
Path : ~/portal-service

ssh ubuntu@10.10.10.92

10서버 목록
https://okestro.atlassian.net/wiki/spaces/DX2/pages/1268350991/DI+Infra

----------------------------------------------------------------------------------------------------

ssh 접속정보

- ID : root
- PW : okestro2018

----------------------------------------------------------------------------------------------------

젠킨스 (http://devops.okestro.cloud:8080/job/vista-portal-service/)

vista_admin / vista

----------------------------------------------------------------------------------------------------

오픈서치 (https://34.22.77.58:5601/)

admin / admin

----------------------------------------------------------------------------------------------------

redis 정보

DEV 
- IP : 34.123.196.65

STG
- IP : 35.184.63.86

서버 스펙은 두 서버 모드 2코어 8GB 입니다!

----------------------------------------------------------------------------------------------------

idc환경정보

재원:
 - CPU: 24 core
 - MEM: 128G
 - DISK: 4TB + 1TB


IP: 101.202.35.180

OS: ubuntu 22.04 LTS

 

접속 정보

SSH:

IP: 101.202.35.180

ID: 개별 사용자 ID

Key: 개발 사용자 Key 발급 필요

Sudo Password: okestro2018

 

설치된 소프트웨어

Postgresql

Micro K8S

Jenkins
	URL: http://jenkins.vista.astellu.com
	계정 발급문의: 홍성철, 한동호, 김명길

Multipass

Harbor
	URL: https://harbor.vista.astellu.com
	계정 발급 문의: 홍성철, 한동호, 김명길

ArgoCD: https://argocd.vista.astellu.com
	ID: admin
	PW: Okestro2018!@

Redis
	IP: 101.202.35.180
	PORT: 6379
	PASSWD: okestro2018

Filebeat(파일 비트)
	Host : 192.168.0.170
	User : ubuntu
	PW : okestro2018
	파일비트 경로 : /usr/local/src/filebeat
		시스템 로그 폴더 : modules.d/
		커스텀 로그 경로 : inputs.d/
		(파일명 맨 뒤의 .disabled의 의미는 현재 사용되지 않는 설정파일이라는 뜻. 단순히 확장자를 무효화시키기 위해 붙인것이며, .disabled는 비활성화라는걸 명시)

----------------------------------------------------------------------------------------------------

비트버킷 토큰

ATBBNsxBCK2q3kLRPMuUmQ7MvzNCBBA1A659

----------------------------------------------------------------------------------------------------

git pull --rebase 가 뭔지, 어떤 상황에 쓰는 명령어인지 구글링

회사에서는 스프링 웹플럭스, 스프링 웹소켓, jpa + querydsl 을 사용함. 공부하기

스프링부트 프로필 구글링해보기

----------------------------------------------------------------------------------------------------
 
커밋메시지 맨 앞에 지라 ID 넣어놓기 (이렇게 하면 아틀라시안-지라 에서 ID를 검색해서 해당하는 커밋내역들, 변경사항을 확인할 수 있음)
stage 커밋메시지 잘 작성하기

dev에 푸시하면 자동배포됨
master 에서 브랜치 따고 작업후 마스터브랜치에 병합시켜서 푸시하고
로컬에서 테스트 하고 master브랜치로 빌드해서 10서버에 배포하고 테스트 하고
dev 브랜치에 병합시켜서 테스트 하고
stage 브랜치에 병합시켜서 목요일에 배포 되면 테스트

dev, stage 는 GPC 와 쿠버네티스를 사용함

파이프라인이 빗버킷이 있는데, dev브랜치랑 stage브랜치가 있음

dev브랜치는 푸시만 하면 자동배포됨 (테스트는 dev브랜치에서 잘 안하고 로컬이나 10서버에서 하면 됨)


모니터링 하는 팀
터미널에서 해당 가상머신의 정보(CPU사용량, 메모리 사용량, 디스크사용량)를 가져와서 모니터링 시스텝으로 보여주는 작업을 함
시각화는 프론트엔드쪽에서 해주심

VM(가상머신)에 에이전트라는걸 설치해서 VM에 있는 시스템정보들을 가져옴

에이전트를 설치하면 시스템정보들이 오픈서치(검색엔진&noSql)로 자동으로 넘어감

메타데이터나 다른 정보는 PostgreSQL을 씀
시계열 데이터(특정 시간에 계속 가져오는 데이터)를 DB에 넣으면 양이 많기때문에 오픈서치에 넣고



오픈서치랑 포스터그레SQL 에서 정보를 가져와서 프론트엔드쪽에 넘기는 업무를 함

ELKB

백엔드 서비스가 있고
오픈서치가 있고 (엘라스틱서치랑 

-----

다른팀에서 배포해달라고 하면 10서버에 배포

----------------------------------------------------------------------------------------------------

배포(vista-portal-service 프로젝트 기준)

------------------------------

테스트 순서

로컬 → master(개발할때 내부테스트하는용도?) → 101서버 수동배포 → dev → stage(운영)

10서버에 배포할때는 master브랜치 병합해서 빌드하고 만약에 뭔가 테스트결과가 이상할때는 dev에 병합해서 빌드해보기

순서로 배포해서 테스트 하면 되는데 dev는 일주일에 한번정도로만 병합&푸시해놓으면 됨

목요일에는 stage에 잘 푸시해놓는거 잊지말기

------------------------------

로컬에서 실행

스프링부트 메인클래스(@SpringBootApplication 있는 클래스)에서 실행시키는데 실행시키기전에 먼저

Edit Configurations... 클릭하면 나오는 설정창에서
Active profiles 입력란에 설정하고 싶은 yml파일의 -(대쉬)뒤에 있는 문자열을 그대로 입력하고 OK 누르면 실행환경이 알아서 해당 yml로 설정됨

설정파일을
application-local 로 하고 싶으면 local
application-dev 로 하고 싶으면 dev
application-prod 로 하고 싶으면 prod
application-stg 로 하고 싶으면 stg

설정 후 실행하면 됨

------------------------------

master 서버는 로컬테스트용도로 사용. 푸시해도 뭐가 테스트할수 있는 서버가 없음

------------------------------

10서버 배포시

그래들창 열고
main-module > Tasks > build > bootJar 클릭하면

아래의 경로에 jar파일이 생성됨
main-module/build/libs/main-module-0.0.1.jar

이 jar파일을 원격서버에 올리면 되는데

파일질라로 접속해서 파일전송하거나

터미널에서 scp명령어로 파일 원격서버에 전송하면 됨
scp /Users/imchaewon/git/vista-portal-service/main-module/build/libs/main-module-0.0.1.jar ubuntu@10.10.10.92:~/portal-service
cloud1234

시분초의 '시' 에다가 9를 더하면 올린 시각이 한국시간으로 나옴

전송됐으면 ~/portal-service 에 접속해서
ssh ubuntu@10.10.10.92
cloud1234
cd ~/portal-service

아래명령어 2개 입력해서 서버 껏다켜면 됨
sudo ./launcher.sh stop
sudo ./launcher.sh start

-----

배포가 잘 됐는지 확인하는 방법

방법1. 웹에서 테스트
10.10.10.28/#/events

방법2.
yml 파일에 logging: file: name: 여기에 쓰여있는 경로에 있는 파일을
tail 명령어 로 실행

tail -f 파일명

브라우저에서 10.10.10.28/#/events 들어가서 새로고침했을때 정보를 불러오는데, 이때 로그들이 출력되는걸 확인하면 됨


DB 확인할때는
vi launcher.sh 에서

PROFILE=dev 를
PROFILE=local 로
잠시 바꿔서
서버 껏다켜서 확인후
다시 원래대로 돌려놓고 서버껏다켜야함

------------------------------

dev 서버 배포시

파이프라인이 구축되어 있기 때문에
깃으로 빗버켓에 푸시만 하면 자동으로 배포됨

테스트용 url
https://dev.maestro-admin.okestro.cloud/local/vista/portal/v1/

배포가 잘 됐는지 확인은 빗버캣 파이프라인페이지에 들어가면 있음
http://devops.okestro.cloud:8080/

------------------------------

stage 서버 배포시

stage는 푸시해놓으면 목요일 점심먹고나서(오후 2시쯤)에 devOps팀에서 배포해줌

----------------------------------------------------------------------------------------------------

마에스트로 비스타 에이전트 관리

호스트 : om_vm2
ubuntu / okestro2018

----------------------------------------------------------------------------------------------------

테스트 커버리지 툴

실제 운영 코드중에서
테스트코드에 포함되어있는 코드가 얼마나 되는지. 몇 %인지. 어느부분들을 테스트 하는지 알 수 있음

이때 success / fail 여부는 상관없이 그냥 테스트코드에 포함되어있는지만 체크됨

회사에서는 테스트 커버리지 툴로 자코코(jacoco) 를 씀

----------------------------------------------------------------------------------------------------

vista-portal-service 프로젝트에서는 주로 jpa + 쿼리dsl 을 사용함

vista-portal-service의 하위 프로젝트인 common-module 프로젝트에서

그래들창에서 common-module > Task > build > build 클릭하면
common-module > main 에 q클래스 패키지가 생성됨
↓
그냥 run 하면 알아서 q클래스가 생김

----------------------------------------------------------------------------------------------------

Elasticsearch

실시간 분산 검색 및 분석 엔진

대량의 데이터를 저장하고 검색하며, JSON 문서를 사용하여 데이터를 색인화함
특히 텍스트 및 구조화된 데이터의 검색 및 검색 엔진으로 널리 사용됨
Elasticsearch는 빠른 검색 및 집계 기능을 제공하며, 고가용성, 확장성, 데이터 복제, 분산 아키텍처 등 다양한 기능을 갖추고 있음

------------------------------

Logstash

데이터 수집기

데이터 수집, 변환 및 전달 파이프라인을 구축하는 데 사용됨
다양한 데이터 소스로부터 데이터를 수집하고 필요한 형식으로 가공한 후 Elasticsearch 또는 다른 저장소로 전송함. 데이터 파싱, 필터링, 정규화 및 변환을 수행하는 데 특히 유용함
Logstash는 다양한 입력, 필터 및 출력 플러그인을 지원하므로 데이터 처리 파이프라인을 맞춤 설정할 수 있음

------------------------------

Kibana

Elasticsearch 데이터를 시각적으로 탐색하고 대시보드를 생성하는 데 사용되는 웹 인터페이스
사용자는 Kibana를 통해 데이터를 검색, 시각화하고, 대시보드를 구성하여 데이터를 모니터링하고 분석할 수 있음

------------------------------

Beats

경량 데이터 수집 에이전트

다양한 종류의 데이터를 수집하고 Elasticsearch 또는 Logstash로 전송하는 역할을 합니다. Beats에는 다음과 같은 서브 에이전트가 포함되어 있음

Filebeat: 로그 파일과 같은 텍스트 데이터를 수집함
Metricbeat: 시스템 및 서비스의 성능 지표 데이터를 수집함
Heartbeat: 서비스의 가용성을 모니터링함
Winlogbeat: Windows 이벤트 로그 데이터를 수집함
Packetbeat: 네트워크 패킷 데이터를 분석하고 수집함

Beats는 경량이고 손쉽게 설정할 수 있으며, 다양한 데이터 소스로부터 데이터를 캡처하고 Elasticsearch 또는 Logstash로 전송하는 데 사용됨

----------------------------------------------------------------------------------------------------

스프링으로 mybatis설정했을때도 alias설정가능
```
<select id="selectUserList" resultType="com.okestro.vista.portal.model.user.UserDTO">
```
을 아래처럼 쓸 수 있음
```
<select id="selectUserList" resultType="UserDTO">
```
설정하는 자바코드부분이고, .setTypeAliasesPackage()메서드로 설정하면됨

@MapperScan(
        value = {PortalConfigConst.EnvPath.MYBATIS_BASE_PACKAGE,},
        sqlSessionFactoryRef = PortalConfigConst.Mybatis.SESSION_FACTORY
) //mybatis settings
@EnableTransactionManagement
@Configuration
public class PortalDBConfig {
	.
	.
	@Primary
	@Bean(name = PortalConfigConst.Mybatis.SESSION_FACTORY)
	public SqlSessionFactory vistaSqlSessionFactory(
			@Qualifier(PortalConfigConst.DATASOURCE) DataSource vistaDataSource,
			ApplicationContext applicationContext
	) throws Exception {
		SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();
		sqlSessionFactoryBean.setDataSource(vistaDataSource);
		sqlSessionFactoryBean.setConfigLocation(new PathMatchingResourcePatternResolver().getResource(PortalConfigConst.EnvPath.MYBATIS_CONFIG));
		sqlSessionFactoryBean.setMapperLocations(applicationContext.getResources(PortalConfigConst.EnvPath.MYBATIS_RESOURCE));
	
		// 클래스 alias 설정
		sqlSessionFactoryBean.setTypeAliasesPackage("com.okestro.vista.portal.model.user");
	
		return sqlSessionFactoryBean.getObject();
	}
}

----------------------------------------------------------------------------------------------------

mybatis에서 select할때

resultType으로 dto에 담을때 컬럼명이 자동으로 스네이크케이스에서 카멜케이스로 바뀜

그래서 dto에 필드만들때 카멜케이스로 작성해야함

----------------------------------------------------------------------------------------------------

postgresql에서 timestamp 타입으로 저장되어있는걸 select할때

resultType으로 dto에 담을때

dto에서 날짜 필드를 String으로 받아도 되고, java.sql.Timestamp로 받아도 됨

String으로 받으면 2023-09-13 12:21:40.529101 이렇게 받아지고
java.sql.Timestamp로 받으면 1694750820122 이런식으로 13자리 타임스탬프형식으로 받아짐

----------------------------------------------------------------------------------------------------

유효성검사

DTO에서 검증하는 어노테이이션(jakarta.validation.constraints) 붙이고

@NotNull(message = "이름은 필수 입력 값입니다.")
private String userName;
@Email(message = "이메일 형식에 맞지 않습니다.")
private String email;


컨트롤러에서 아래처럼 검증이 필요한곳에서만 @Vaild로 쓸 수 있음. @Valid를 안붙이면 DTO에 @NotNull 등의 어노테이션을 붙이지 않았을때와 똑같이 동작됨
```java
asd
```
@PostMapping
	public ResponseEntity<?> registerUser(@Valid @RequestBody UserDTO reqDTO) {
``

그럼 api요청할때 유효성검사를 해서 통과되지않았을경우 400(Bad Request) 를 응답함


참고: https://mangkyu.tistory.com/174
참고: https://victorydntmd.tistory.com/332

----------------------------------------------------------------------------------------------------

메트릭

하드웨어나 소프트웨어에 대한 성능 측정을 위한 측정 수치값
때문에 꼭 필요한 요소로서 타임스탬프(이벤트발생시간)과 수치(숫자) 가 있음

2023-06-18 18:00:00, CPU사용률 85%
위와같이 해당 시각 또는 기간의  성능 측정을 위해 필요한 수치를 말함

메트릭은 주기적으로 발생하여 모니터링 할 수 있으며, 소프트웨어 등의 성능 모니터링에 광범위하게 사용됨

대표적인 수집 모니터링 어플리케이션으로는
∙elasticsearch를 사용하는 metricbeat
∙prometheus가 있음

----------------------------------------------------------------------------------------------------

Metricbeat(메트릭 비트) : 자원 상태(CPU, Memory)
Filebeat(파일 비트) : 로그 수집

----------------------------------------------------------------------------------------------------

비스타 백엔드
- 사용자 CRUD
- 이벤트 규칙생성

이벤트가 발생했을때 알림전송

이벤트규칙 생성시 vt_event_rule

장애가 발생했을때 알림이 가야함

rule-engine 모듈(프로젝트)은 event_rule등의 테이블이 정의되어있는걸 보고
매트릭 정보(카프카 - 튜바토픽) 를 감지해서 처리함

만약 룰엔진에서 이벤트를 감지하면
vt_event - 이벤트가 발생된 내역

스트리밍 엔진 안에
stream-data-porc가 토픽을 리스닝함
stream-rule-proc

스트리밍엔진은 카프카에 빨대를 꽂고 데이터가 들어오는지 리스닝을 함

그다음 vt_event 테이블에 넣음

그다음 이벤트 푸셔에 알림을 줌


메시지 구조
이벤트아이디 하나만 보냄 (이벤트 푸셔라는 토픽으로 카프카에 데이타를 보냄)
그걸 승환님이 구독을 하시고 이메일이나 슬랙에 알림을 보내줌



비스타백앤드
룰엔진
스트리밍엔진(데민)
승환님쪽(go 언어)


발생 내역 = vt_event


MSA 구조 정리

1. 비스타 관리자 사이트에서 호스트, 메트릭의 특정 조건, 알림 수신자에 대한 이벤트 발생 규칙을 생성해서 [event_rule]&[event_rule_user]테이블에 등록함 (ex. 메모리 사용량 30%)
2. "델타엔진(delta-engine)"은 "튜바메트릭토픽(tuba-metric-topic)"을 구독하고있고(실시간으로 "튜바메트릭토픽(tuba-metric)"에서 데이터를 가져오고 있고) "델타토픽(delta-topic)"을만듦
3. "룰엔진(rule-engine)"은 "델타토픽(delta-topic)"을 구독하고있고 "이벤트펍(event-pub)"토픽을 프로듀싱함
4. "스트리밍엔진(streaming-engine)" 은 "이벤트펍(event-pub)을 구독하고있다가 데이터가 오면 [vt_event]테이블에 저장하고, 이벤트테이블에 생성된 데이터의 pk를 함께 "트리거펍(trigger-pub)"토픽을 프로듀싱함
5. "이벤트푸셔(event-pusher)" 는 "트리거펍(trigger-pub)"토픽을 구독하고있다가 데이터가 생기면 그 데이터를 이용해 사용자에게 알림을 발송함

------------------------------

아키텍처 구성도 (토픽 관계)
https://okestro.atlassian.net/wiki/spaces/DX2/pages/1269563994/DI+BE

----------------------------------------------------------------------------------------------------

거버넌스 (데이터 제공 명세)

https://docs.google.com/spreadsheets/d/1ZDm_iBtvFEr26VupNPKSw5DrKJq0f7Jm/edit#gid=123612737

어떤어떤 매트릭을 수집하며, 데이터가 어떤식으로 들어오는지 예제도 포함되어있음

에이전트 - 상욱님
에이전트 리스(less) - 현수님

----------------------------------------------------------------------------------------------------

토픽 정리

maestro_dev & maestro_stg
http://10.10.10.237:8989/ui/clusters/maestro_dev/all-topics?perPage=25

----------------------------------------------------------------------------------------------------

그라파나

오픈소스 데이터 시각화 및 모니터링에 특화된 도구

엘라스틱서치 : 검색 및 분석엔진(데이터 수집, 처리)

그라파나
시각화에 특화된 도구. 고급 시각화, 대화형 차트, 템플릿, 트릭스 등 다양한 플러그인 제공
여러 데이터소스를 통합해서 모니터링 가능 (RDB, 엘라스틱서치, 프로메테우스 등)
데이터의 이상 상태를 감지하고 알림 및 경고를 설정할 수 있는 기능을 제공함. (엘라스틱서치에는 없음)

http://maestro-proxy.okestro.cloud:30076/d/sadlil-loki-apps-dashboard/logs-app?orgId=1&var-app=vista%2Fvista-rule-engine-delta-engine-daemon-5855cfbdfd-7z9lt&var-search=&from=now-30m&to=now

vista / vista

----------------------------------------------------------------------------------------------------

에이전트(agent) : 데이터를 수집하는 소프트웨어 프로그램
파일비트(filebeat) : 엘라스틱서치의 에이전트
호스트 : VM(가상머신)이 실행되는 물리적인 머신(컴퓨터, 서버)
VM(가상머신 : 호스트 서버에서 독립적으로 실행되는 가상환경

----------------------------------------------------------------------------------------------------

포스트맨에서 URL&헤더 정보를 한꺼번에 붙여넣을 수 있음

개발자도구 → 네트워크 → 요청항목 우클릭 → 복사 → cURL로 복사 후

포스트맨 → Import → 붙여넣기

★★★Request Headers에서 Accept 키의 값이 */* 이라고 되어있지 않으면 아래와 같은 500에러 발생됨
org.springframework.web.HttpMediaTypeNotAcceptableException: Could not parse 'Accept' header [/]: Invalid mime type "/": does not contain subtype after '/'

----------------------------------------------------------------------------------------------------











